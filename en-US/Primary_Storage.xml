<?xml version='1.0' encoding='utf-8' ?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
<!ENTITY % BOOK_ENTITIES SYSTEM "Best_Practices_Guide.ent">
%BOOK_ENTITIES;
]>
<chapter id="chap-Best_Practices_Guide-Primary_Storage">
	<title>Primary Storage</title>
	<para>
		<indexterm><primary>Primary Storage</primary></indexterm> is the storage used by hypervisors to store virtual machines.  Depending on the hypervisor software, the primary storage could be an NFS share, fiber channel, or...
	</para>
	<section id="sect-Best_Practices_Guide-Primary_Storage-Per_Cluster">
		<title>Primary Storage per Cluster</title>
		<para>
			Primary storage mountpoints or LUNs should not exceed 6 TB in size.  It is better to have multiple smaller primary storage elements per Cluster than one large one.
		</para>
		<para>
			When exporting shares on primary storage, avoid data loss by restricting the range of IP addresses that can access the storage.
		</para>
		<para>
			Monitor host disk space.  Many host failures occur because the host's root disk fills up from logs that were not rotated adequately.
		</para>
	</section>
	<section id="sect-Best_Practices_Guide-Primary_Storage-Utilizing_RAID">
		<title>Utilizing RAID</title>
		<para>
			It is important that the storage server contain many large disks and use a hardware <indexterm><primary>RAID</primary></indexterm> controller.  Hardware RAID is faster than software RAID and has the added bonus of supporting hot plug functionality independent of the operating system so you can replace faulty disks without impacting the running operating system.
		</para>
        </section>
        <section id="sect-Best_Practices_Guide-Primary_Storage-Limiting_NFS_Export">
		<title>Limiting NFS Export</title>
		<para>
			It is highly recommended that you limit the NFS export to a particular subnet by specifying a subnet mask (e.g.,"192.168.1.0/24"). By allowing access from only within the expected cluster, you avoid having non-pool member mount the storage. The limit you place must include the private network(s) and the storage network(s). If the two are the same network then one CIDR is sufficient. If you have a separate storage network you must provide separate CIDR's for both or one CIDR that is broad enough to span both.
		</para>
		<para>
			<command># echo "/export CIDR(rw,async,no_root_squash)" >> /etc/exports</command>
		</para>
		<para>
			The following is an example with separate CIDRs:
		</para>
			<itemizedlist>
				<listitem>
					<para>
						<command>/export 192.168.1.0/24(rw,async,no_root_squash) 10.50.1.0/24(rw,async,no_root_squash)</command>
					</para>
				</listitem>
			</itemizedlist>
		<para>
			Removing the async flag. The async flag improves performance by allowing the NFS server to respond before writes are committed to the disk. Remove the async flag in your mission critical production deployment.
		</para>
		<para>
			The volumes used for Primary and Secondary storage should be accessible from Management Server and the hypervisors. These volumes should allow root users to read/write data.  These volumes must be for the exclusive use of CloudStack and should not contain any data.
		</para>
	</section>

</chapter>

